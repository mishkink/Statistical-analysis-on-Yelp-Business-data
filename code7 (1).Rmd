# **Yelp Business Dataset EDA**
### *Mishkin Khunger, Sanat Lal, Sharmin Kantharia, Vishal Pathak*



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## **Chapter 1: Introduction**
Yelp is a business directory service and crowdsourced review forum. This dataset includes data related many domains – business, checkin, review, tip, user. We have made use of the business data for initial EDA. The data consists of 1,92,000 rows.

### **Smart Questions:**
1. Is Star Rating a significant contributor in deciding whether a
business will stay active or will discontinue?
2. Yelp owns numerous types of business. We aim to determine
the most popular Yelp business for which the user makes use of
the yelp application to provide useful ratings and reviews.
3. Is there a significant relationship between the number of
reviews received and the ratings obtained, do the ratings
increase with the increase in the number of review counts?
4. Is Yelp uniformly distributed among the whole North America
or is it just prominent in some selected states?

```{r data_load,include=FALSE,echo=FALSE}
library(jsonlite)
yelpbusines <- stream_in(file("business.json"), pagesize = 200000)

#str(yelpbusines)
yelpbusines_flat <-flatten(yelpbusines)
```

```{r datasubset, echo=FALSE}
columnnames <- colnames(yelpbusines_flat)

columnnamesusing <- columnnames[1:20]
#columnnamesusing

yelpbusines_flat_dataused <- yelpbusines_flat[columnnamesusing]
# subset data 

#yelpbusines_flat_dataused 

# data on which we will work
#str(yelpbusines_flat_dataused)
colnames(yelpbusines_flat_dataused)

# removing columns which has no relevance 
yfdn <- subset(yelpbusines_flat_dataused, select = -c(1,3,13,14,15,16,17,18,19,20))
# after removing few more column which we wont be using 
#yfdn
#colnames(yfdn)
```



## **Chapter 2: Data Cleaning**
To clean this data, we found the NA values in each column and deleted those rows, thereby getting a new dataframe. In this new dataframe, the categories column consists of many sub-categories. We split the categories and see that since there are 1000 comma -seperated values which maybe similar to each other but differ by name hence, we cannot implement one hot encoding. Then we grouped these 1000 comma-separated values in to 10 major categories. 

The business data consist of many columns, out of which we are working on the following:
1. Name
2. City
3. State
4. Latitude
5. Longitude
6. Stars
7. review_count
8. is_open
9. Categories

```{r datacheck,include=FALSE, echo=FALSE}
sum(is.na(yfdn$name))
sum(is.na(yfdn$city))
sum(is.na(yfdn$state))
sum(is.na(yfdn$latitude))
sum(is.na(yfdn$longitude))
sum(is.na(yfdn$stars))
sum(is.na(yfdn$review_count))
sum(is.na(yfdn$is_open))
sum(is.na(yfdn$categories))

yfdn <- na.omit(yfdn)
```

```{r naremoval, echo=FALSE}
# NA value rows removal
yfdn <- na.omit(yfdn)
```

```{r categorycol, echo=FALSE}
# categories created for category column
yfdn$categories[grepl("Restaurants",yfdn$categories)] <- "1"
yfdn$categories[grepl("Nightlife",yfdn$categories)] <- "1"
yfdn$categories[grepl("Food",yfdn$categories)] <- "1"
yfdn$categories[grepl("Bakeries",yfdn$categories)] <- "1"
yfdn$categories[grepl("Automotive",yfdn$categories)] <- "2"
yfdn$categories[grepl("Spa",yfdn$categories)] <- "3"
yfdn$categories[grepl("Salons",yfdn$categories)] <- "3"
yfdn$categories[grepl("Education",yfdn$categories)] <- "4"
yfdn$categories[grepl("Churches",yfdn$categories)] <- "4"
yfdn$categories[grepl("Religious",yfdn$categories)] <- "4"
yfdn$categories[grepl("Book",yfdn$categories)] <- "4"
yfdn$categories[grepl("Active Life",yfdn$categories)] <- "5"
yfdn$categories[grepl("Hotels",yfdn$categories)] <- "6"
yfdn$categories[grepl("Real Estate",yfdn$categories)] <- "6"
yfdn$categories[grepl("Shopping",yfdn$categories)] <- "7"
yfdn$categories[grepl("Entertainment",yfdn$categories)] <- "7"
yfdn$categories[grepl("Stores",yfdn$categories)] <- "7"
yfdn$categories[grepl("Services",yfdn$categories)] <- "8"
yfdn$categories[grepl("Pet",yfdn$categories)] <- "8"
yfdn$categories[grepl("Health & Medical",yfdn$categories)] <- "9"
yfdn$categories[grepl("Stations",yfdn$categories)]<- "10"
yfdn$categories[grepl("Media",yfdn$categories)]<- "10"
yfdn$categories[grepl("Public Art",yfdn$categories)]<- "10"
yfdn$categories[grepl("Local Flavor",yfdn$categories)]<- "10"
```



## **Chapter 3: Graphical Representation** 
In order to work with certain columns such as is_open and categories, we convert them into factors. This allows us to perfrom visualization on them efficiently.

```{r convert,include=FALSE,echo=FALSE}
#str(yfdn$categories)
sum(is.na(yfdn$categories))
as.numeric(yfdn$categories)
yfdn <- na.omit(yfdn) 
#$Converting data set into factor()
yfdn$is_open <- as.factor(yfdn$is_open)
yfdn$categories <- as.factor(yfdn$categories)
#str(yfdn$is_open)
#str(yfdn$categories) 
```

# EHHH

```{r fig.cap= "city vs categories", echo=FALSE}
library("ggplot2")
p <- ggplot(aes(x=city, y=categories), data=yfdn)+ geom_point()
p + ggtitle("Star Ratings for each Category", xlab = "Categories", ylab = "Stars" )
```

### *Graph:*
The EDA on the States shows that businesses covered under Yelp are most prominent in the states of Arizona, North Carolina, Quebec and Illinois.

```{r fig.cap= " Barplot of state ", echo=FALSE}
 site.freq <- table(yfdn$state)
 barplot(site.freq , decreasing = T)
 barplot(site.freq[order(site.freq,decreasing = T)],space = c(7,7,7,7,7),col = rainbow(20),xlab='State', ylab='Frequency')
``` 

# EHHH
```{r fig.cap= "state vs star", echo=FALSE}
ggplot(aes(y=state,x=stars),data=yfdn)+ geom_point()
```


### *Graph:*
There is a varied distribution of ratings across different states which suggests that the location of a business has an impact on it's rating.

```{r fig.cap= " Boxplot of star vs State", echo=FALSE}
boxplot(yfdn$stars~yfdn$state, xlab = 'States' , ylab = 'Stars', main = 'Star Ratings in each State', col= "Blue")
```

### *Graph:*
It can be concluded that for high number of review counts the average
ratings is 4. We can also see that 5 star rating in terms of review counts
is fairly low, while most of them ranging between 3.0 & 4.5.

```{r fig.cap= " plot of star vs Review count", echo=FALSE}
library("ggplot2")
plot(review_count~stars , data= yfdn, col= "red")
typeof(yfdn$review_count)
```

### *Graph:*
By looking at the Box plot between Star Ratings and Active Businesses we can conclude that there is no direct relationship between Star Ratings and the discontinuation of a particular business. This is because, even after achieving higher ratings some businesses have been discontinued. This implies that there may be other factors such as relocation, labor scarcity, increased state taxes, demand of business, automation of services, which may have contributed to the shut down.

```{r fig.cap= " Boxplot of star vs is_open", echo=FALSE}
boxplot(yfdn$stars~yfdn$is_open, xlab = 'Is_Open' ,ylab = 'Stars',main = 'Active Business Vs Stars', col= "yellow")
```

### *Graph:*
Previously, our analysis showed that the highest reviewed Yelp business is that of Restaurants. However, from the boxplot below, we can find which business have received 5 star ratings. These are Pet Services and Gym & Active life.

```{r fig.cap= " Boxplot of state vs categories", echo=FALSE}
boxplot(yfdn$stars~yfdn$categories, xlab = 'Categories' ,ylab = 'stars',main = 'Categories Vs Stars', col= "orange")
```

### *Graph:*
In terms of review count, the top 6 businesses were evaluated, and all the 5
businesses appeared to be from the category Restaurant, with over 5000 review counts. The names of these restaurants are:
1. Mon Ami Gabi
2. Bacchanal Buffet
3. Wicked Spoon
4. Hash House A Go Go
5. Gordon Ramsay BurGR
6. Earl of Sandwich

```{r fig.cap= "Piechart of top rated business ", echo=FALSE}
# Topratedbusiness
yfdn_top5 <- yfdn[order(-yfdn$review_count),]
yfdn_top5 <- head(yfdn_top5)
yfdn_top5

library(RColorBrewer)
myPalette <- brewer.pal(6, "Set2") 

# You can change the border of each area with the classical parameters:
pie(yfdn_top5$review_count , labels = c("Mon Ami Gabi(8348)","Bacchanal Buffet(8339)","Wicked Spoon(6708)","Hash House A Go Go(5763)","Gordon Ramsay BurGR(5484)","Earl of Sandwich(5075)"), border="White", col=myPalette, main = "Piechart of top rated business" )
```

### *Graph:*
Using the library ggmap and the columns latitude and longitude (of the different businesses), we were able to plot the businesses on the map of United States using Google Maps. The density of each individual business in each state and their star ratings can be visualized by this map.

```{r fig.cap= " locating business cordinates on Google Maps", echo=FALSE}
# Plotting Business Cordinates on GOOGLE Maps

#if(!requireNamespace("devtools")) install.packages("devtools")
#devtools::install_github("dkahle/ggmap", ref = "tidyup", force=TRUE)

library("ggmap")
ggmap::register_google(key = "AIzaSyD7CbCCHcChmUSZFT_rZKq2mma0QE65uRU")
library(ggplot2)
p <- ggmap(get_googlemap(center = c(lon = -95.7128906, lat = 37.090241),
                         zoom = 4, scale = 2,
                         maptype ='terrain',
                         color = 'color'))
p + geom_point(aes(x = as.numeric(longitude), y =as.numeric(latitude) ,colour = stars ), data = yfdn, size = 0.5) + 
  theme(legend.position="bottom")
  typeof(yfdn$latitude)

```

# EHHHHh
```{r fig.cap= " GGplot(boxplot) of Review count and categories ", echo=FALSE}
boxplot(yfdn$review_count~yfdn$categories, xlab = 'Category' ,ylab = 'Review Count',main = 'Categories vs Review Count', col= "blue")
```

 # review_count vs category  Restaurants & hotel/Real state services are highly reviewd which may suggests that they have the highest market amongst these categories and people expect a lot from these businesses
 
 
 
## **Chapter 4: Descriptive Statistics** 
Using the summary(), we care able to see the various statistical descriptions of the selected columns. For factor variables, we see the values counts of the different levels. For numerical variables, we can see the Minimum, Maximum, 1st and 3rd Quantiles, Mean and Median. For character variables we can see the length of each column and their data types or class.  

```{r Summary, echo=FALSE}
summary(yfdn) 
```
 
We now check the normality of the dataset with the selected attributes. As we can see, the graph shows that Star Ratings are not normally distributed as anticipated. Moreover, the curve is slightly Left-Skewed.

```{r fig.cap= " Normality check", echo=FALSE}
my_hist=hist(yfdn$stars , breaks=40  , plot=F)
# Color vector
my_color= ifelse(my_hist$breaks < 2.5, rgb(0.2,0.8,0.5,0.5) , ifelse (my_hist$breaks > 4, "purple", rgb(0.2,0.2,0.2,0.2) ))
# Final plot
plot(my_hist, col=my_color , border=F , main="" , xlab="value of the variable", xlim=c(1,5) )
```
 
```{r Descrptivestats, echo=FALSE, include=FALSE}
# Descriptive stats of numerical Variables
# We calculate these values, but they are not used, as the statistical testing gives appropriate results on its own
sd(yfdn$city)
var(yfdn$city)
sd(yfdn$state)
var(yfdn$state)
sd(yfdn$postal_code)
var(yfdn$postal_code)
sd(yfdn$latitude)
var(yfdn$latitude)
sd(yfdn$longitude)
var(yfdn$longitude)
sd(yfdn$stars)
var(yfdn$stars)
sd(yfdn$review_count)
var(yfdn$review_count)
```

### **Testing**

### *Test 1: Welch Two Sample t-test:*
#### *Compares: Stars vs. Review_Count*

H0 : Review count for each star rating are equally distributed.
H1 : Review count for each star rating are not equally distributed.
Null hypothesis is rejected.

### *Analysis:*

The SMART question that asks of the relationship between the ratings and review
counts, can be explained here. Since, the reviews are unequally distributed amongst
the ratings, we cannot conclude that, as the number of rating increases, for a particular business, it’s rating will improve as well.

```{r tteststarandreviewcount , echo=FALSE}
stars_sample <- yfdn(stars, 30, replace = TRUE)
reviewcounts_sample <- yfdn(review_count, 30, replace = TRUE)
t.test(yfdn$stars,yfdn$review_count )
```

### *Test 2: Chi – Squared Test:*
#### *Compares: City vs. Category*

H0 : Business categories are equally distributed in each city.
H1 : Business categories are not equally distributed in each city.
Null hypothesis is rejected.

### *Analysis:*

We have 10 different categories of business. For example:- Restaurant/Nightlife… is
category 1, etc. We are trying to find whether the different businesses are equally
distributed in each city or not, out of the 36 states taken into consideration for our purpose.

```{r chisq_city&cat, echo=FALSE}
chisq.test(yfdn$city , yfdn$categories, simulate.p.value = TRUE, correct = TRUE)
```

### *Test 3: ANOVA Test*
#### *Compares: Review_Count vs. Category*

H0 : Different business categories have equal number of reviews.
H1 : Different business categories have different number of reviews.
Null hypothesis is rejected.

### *Analysis:*

Different business categories have unequal number of reviews, which means reviews are not equally distributed across various categories.

```{r anovabetween_reviewcount_categories , echo=FALSE}
aov2<- aov(review_count~categories, data = yfdn )
names(aov2)
summary(aov2)
```

### *Test 4: ANOVA Test*
#### *Compares: Stars vs. Category*

H0 : The stars ratings are equally distributed amongst different business categories.
H1 : The stars ratings are not equally distributed amongst different business categories.
Null hypothesis is rejected.

### *Analysis:*

Different business categories have unequal star ratings, which means ratings are not equally distributed across various categories.

```{r anovabetweenstar&cat, echo=FALSE}
aov3 <- aov(stars~categories , data = yfdn)
names(aov3)
summary(aov3)
```



## **Chapter 5: Limitations** 
Despite finding an answer to our SMART Questions, we came across certain limitations during our analysis, in terms of our data. These were:
1. Our data was extremely unclean which resulted in very time-consuming data cleaning. This propelled us to eliminate several rows and columns with NA values.
2. Due to elimination, we were able to work with only 36 states out of the total 50 states. Hence, in order to perform a country-wide search we would require a much cleaner dataset.
3. Our SMART questions did not include a Time-series question. This is because the dataset chosen for EDA did not consist of a time-specific attribute.



## **Chapter 6: Future Work**
The Yelp dataset consists of sub-domains such as Business, Checkin, Reviw, Tip and User. Each of these sub-datasets consist of a large number of datapoints. For initial EDA and Phase 1 of the project, we chose the Business Dataset. However, given the scope of answering several other questions in Phase 2, we aim to make use of multiple attributes from most of the sub-datasets and combining them to create a single dataset, which allows us to answer our questions and maybe even find something new!  


